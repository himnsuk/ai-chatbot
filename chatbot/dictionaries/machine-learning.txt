a/b testing,
accuracy,
action,
activation function,
active learning,
adagrad,
agent,
agglomerative clustering,
ar,
area under the pr curve,
area under the roc curve,
artificial general intelligence,
artificial intelligence,
attribute,
auc,
area under the roc curve,
augmented reality,
automation bias,
average precision,
backpropagation,
bag of words,
baseline,
batch,
batch normalization,
batch size,
bayesian neural network,
bellman equation,
bias (ethics/fairness),
bias (math),
bigram,
binary classification,
binning,
boosting,
bounding box,
broadcasting,
bucketing,
calibration layer,
candidate generation,
candidate sampling,
categorical data,
centroid,
centroid-based clustering,
checkpoint,
class,
classification model,
classification threshold,
class-imbalanced dataset,
clipping,
cloud tpu,
clustering,
co-adaptation,
collaborative filtering,
confirmation bias,
confusion matrix,
continuous feature,
convenience sampling,
convergence,
convex function,
convex optimization,
convex set,
convolution,
convolutional filter,
convolutional layer,
convolutional neural network,
convolutional operation,
cost,
counterfactual fairness,
coverage bias,
crash blossom,
critic,
cross-entropy,
cross-validation,
custom estimator,
data analysis,
data augmentation,
dataframe,
data set or dataset,
dataset api,
tf.data,
decision boundary,
decision threshold,
decision tree,
deep model,
deep neural network,
deep q-network,
dqn,
demographic parity,
dense feature,
dense layer,
depth,
depthwise separable convolutional neural network,
sepcnn,
device,
dimension reduction,
dimensions,
discrete feature,
discriminative model,
discriminator,
disparate impact,
disparate treatment,
divisive clustering,
downsampling,
dqn,
dropout regularization,
dynamic model,
eager execution,
early stopping,
embeddings,
embedding space,
empirical risk minimization,
erm,
ensemble,
environment,
episode,
epoch,
epsilon greedy policy,
equality of opportunity,
equalized odds,
estimator,
example,
experience replay,
experimenter's bias,
exploding gradient problem,
fairness constraint,
fairness metric,
false negative,
fn,
false positive,
fp,
false positive rate
fpr,
feature,
feature column,
feature cross,
feature engineering,
feature extraction,
feature set,
feature spec,
feature vector,
federated learning,
feedback loop,
feedforward neural network
ffn,
few-shot learning,
fine tuning,
forget gate,
full softmax,
fully connected layer,
gan,
generalization,
generalization curve,
generalized linear model,
generative adversarial network,
generative model,
generator,
gradient,
gradient clipping,
gradient descent,
graph,
graph execution,
greedy policy,
ground truth,
group attribution bias,
hashing,
heuristic,
hidden layer,
hierarchical clustering,
hinge loss,
holdout data,
hyperparameter,
hyperplane,
image recognition,
imbalanced dataset,
implicit bias,
incompatibility of fairness metrics,
independently and identically distributed
i.i.d,
individual fairness,
inference,
in-group bias,
input function,
input layer,
instance,
interpretability,
inter-rater agreement,
intersection over union
iou,
item matrix,
items,
iteration,
keras,
keypoints,
kernel support vector machines
ksvms,
k-means,
k-median,
l1 loss,
l1 regularization,
l2 loss,
l2 regularization,
label,
labeled example,
lambda,
landmarks,
layer,
layers api,
learning rate,
least squares regression,
linear model,
linear regression,
logistic regression,
logits,
log loss,
log-odds,
long short-term memory
loss,
loss curve,
loss surface,
lstm,
machine learning,
majority class,
markov decision process,
mdp,
markov property,
matplotlib,
matrix factorization,
mean absolute error,
mae,
mean squared error
mse,
metric,
metrics api
tf.metrics,
mini-batch,
mini-batch stochastic gradient descent
sgd,
minimax loss,
minority class,
ml,
mnist,
model,
model capacity,
model function,
model training,
momentum,
multi-class classification,
multi-class logistic regression,
multinomial classification,
nan trap,
natural language understanding,
negative class,
neural network,
neuron,
n-gram,
nlu,
node neural network,
node tensorflow graph,
noise,
non-response bias,
normalization,
numerical data,
numpy,
objective,
objective function,
offline inference,
one-hot encoding,
one-shot learning,
one-vs-all,
online inference,
operation,
optimizer,
out-group homogeneity bias,
outliers,
output layer,
overfitting,
pandas,
parameter,
parameter server
ps,
parameter update,
partial derivative,
participation bias,
partitioning strategy,
perceptron,
performance,
perplexity,
pipeline,
policy,
pooling,
positive class,
post-processing,
pr auc,
area under the pr curve,
precision,
precision-recall curve,
prediction,
prediction bias,
predictive parity,
predictive rate parity,
premade estimator,
preprocessing,
pre-trained model,
prior belief,
proxy,
sensitive attributes,
proxy labels,
q-function,
q-learning,
quantile,
quantile bucketing,
quantization,
queue,
random forest,
random policy,
rank ordinality,
rank tensor,
rater,
recall,
recommendation system,
rectified linear unit
relu,
recurrent neural network,
regression model,
regularization,
regularization rate,
reinforcement learning,
rl,
replay buffer,
reporting bias,
representation,
re-ranking,
return,
reward,
ridge regularization,
rnn,
roc curve,
receiver operating characteristic curve,
root directory,
root mean squared error
rmse,
rotational invariance,
sampling bias,
savedmodel,
saver,
scalar,
scaling,
scikit-learn,
scoring,
selection bias,
semi-supervised learning,
sensitive attribute,
sentiment analysis,
sequence model,
serving,
session,
tf.session,
shape tensor,
sigmoid function,
similarity measure,
size invariance,
sketching,
softmax,
sparse feature,
sparse representation,
sparse vector,
sparsity,
spatial pooling,
squared hinge loss,
squared loss,
state,
state-action value function,
static model,
stationarity,
step,
step size,
stochastic gradient descent
sgd,
stride,
structural risk minimization
srm,
subsampling,
summary,
supervised machine learning,
synthetic feature,
tabular q-learning,
target,
target network,
temporal data,
tensor,
tensorboard,
tensorflow,
tensorflow playground,
tensorflow serving,
tensor processing unit
tpu,
tensor rank,
tensor shape,
tensor size,
termination condition,
test set,
tf.example,
tf.keras,
time series analysis,
timestep,
tower,
tpu,
tpu chip,
tpu device,
tpu master,
tpu node,
tpu pod,
tpu resource,
tpu slice,
tpu type,
tpu worker,
training,
training set,
trajectory,
transfer learning,
translational invariance,
trigram,
true negative,
tn,
true positive,
tp,
true positive rate
tpr,
unawareness,
unawareness (to a sensitive attribute),
underfitting,
unlabeled example,
unsupervised machine learning,
upweighting,
user matrix,
validation,
validation set,
vanishing gradient problem,
wasserstein loss,
weight,
weighted alternating least squares
wals,
wide model,
width,
supervised learning,
unsupervised learning,
deep learning,
reinforcement learning,
neural networks,
classification,
regression,
clustering,
model,
algorithm,
model vs algorithm,
attribute,
feature,
feature vector,
instance,
observation,
dimension,
data cleaning,
classifier,
accuracy,
null accuracy,
specificity,
precision,
recall,
precision vs recall,
type 1 errors,
type 2 errors,
classification threshold,
confusion matrix,
linear regression,
evaluating performance of linear regression,
universal approximation theorem,
classifier,
inducer,
induction,
deduction,
interpolation,
extrapolation,
feature selection,
overfitting,
underfitting,
bias and variance,
bias,
variance,
bias-variance tradeoff,
training set,
validation set,
test set,
model validation,
cross-validation,
loss,
epoch,
batch,
iteration,
learning rate,
regularization,
normalization,
fine-tuning,
backpropagation,
dense layer,
algorithm,
analytical validation,
artificial general intelligence (agi),
artificial intelligence (ai),
artificial narrow intelligence (ani),
artificial neural network (ann),
augmented intelligence,
also known as intelligence augmentation (ia),
backpropagation,
bayesian networks,
big data,
chatbots,
classification,
clustering,
cognitive computing,
computer aided detection (cade),
computer aided diagnosis (cadx),
computer vision,
confidence interval,
continuous learning systems (cls),
convolutional neural network (cnn),
data mining,
deep learning,
embodied ai,
expert system,
explainable ai (x.a.i),
false negative,
false positive,
few-shot learning,
forward chaining,
friendly artificial intelligence (fia),
generative adversarial networks (gan),
genetic algorithm,
heuristic search techniques,
image recognition,
inductive reasoning,
intelligence explosion,
knowledge engineering,
limited memory,
machine learning (ml),
machine perception,
machine translation,
narrow intelligence,
natural language processing (nlp),
neural networks,
neuromorphic chip,
optical character recognition (ocr),
pattern recognition,
perceptron,
real time health systems (rths),
recommendation algorithms,
recurrent neural network (rnn),
regression,
reinforcement learning,
robotic process automation (rpa),
robotics,
shadow learning,
singularity,
strong ai,
structured data,
superintelligence,
supervised learning,
tensorflow,
transfer learning,
true negative,
true positive,
turing test,
unfriendly artificial intelligence,
unstructured data,
unsupervised learning,
weak ai,
activation function,
adam optimization,
adaptive gradient algorithm,
average pooling,
alexnet,
backpropagation,
batch gradient descent,
batch normalization,
bias,
classification,
convolution,
cost function,
deep neural network,
derivative,
dropout,
end-to-end learning,
epoch,
forward propagation,
fully-connected layer,
gated recurrent unit,
human-level performance,
hyperparameters,
imagenet,
iteration,
gradient descent,
layer,
learning rate decay,
maximum pooling,
long short-term memory,
mini-batch gradient descent,
momentum,
neural network,
non-max suppression,
recurrent neural networks,
relu,
regression,
root mean squared propagation,
parameters,
softmax,
stochastic gradient descent,
supervised learning,
transfer learning,
unsupervised learning,
validation set,
vanishing gradients,
variance,
vector,
vgg-16,
xavier initialization,
yolo
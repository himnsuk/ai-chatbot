{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "from rake_nltk import Rake\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stopwords_gensim = STOPWORDS.union(set(['likes', 'explain', 'like', 'it\\'s', 'tell']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_reading_multiple_file(path, file_type, column_list,header_type):\n",
    "    path = path\n",
    "    dir_files = glob.glob(path + f\"/*.{file_type}\")\n",
    "    final_df = pd.DataFrame(columns = column_list)\n",
    "\n",
    "    for file_name in dir_files:\n",
    "        print(file_name)\n",
    "        temp_df = pd.read_csv(file_name, header=header_type)\n",
    "        final_df = pd.concat([final_df,temp_df])\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_keyword(sen):\n",
    "    keyword_list = create_n_grams(sen, dictionary_list)\n",
    "    return keyword_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "chatbot/dictionaries/deep-learning.txt\nchatbot/dictionaries/machine-learning.txt\nchatbot/dictionaries/question-tags.txt\nchatbot/dictionaries/data-mining.txt\nchatbot/dictionaries/statistics.txt\nchatbot/dictionaries/artificial-intelligence.txt\n1550\n"
    }
   ],
   "source": [
    "dictionary_directory = \"chatbot/dictionaries\"\n",
    "complete_dictionary = dataframe_reading_multiple_file(dictionary_directory, \"txt\", [], None)\n",
    "complete_dictionary = complete_dictionary.drop(1, axis=1)\n",
    "de_dupe_dict = complete_dictionary.drop_duplicates\n",
    "dictionary_list = complete_dictionary[0].tolist()\n",
    "print(len(dictionary_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_n_grams(question, dictionary_directory):\n",
    "  text = question\n",
    "  tokens = word_tokenize(text.lower())\n",
    "  tokens_without_sw = [word for word in tokens if not word in all_stopwords_gensim]\n",
    "  filtered_unigram = [item for item in tokens_without_sw if item in dictionary_list]\n",
    "  excluded_unigram = [item for item in tokens_without_sw if item not in dictionary_list]\n",
    "  bigrams = list(ngrams(tokens,2))\n",
    "  trigrams = list(ngrams(tokens,3))\n",
    "  fourgrams = list(ngrams(tokens,4))\n",
    "  fivegrams = list(ngrams(tokens,5))\n",
    "\n",
    "  filterd_bigram = [\" \".join(item) for item in bigrams if \" \".join(item) in dictionary_list]\n",
    "  filterd_trigram = [\" \".join(item) for item in trigrams if \" \".join(item) in dictionary_list]\n",
    "  filterd_fourgram = [\" \".join(item) for item in fourgrams if \" \".join(item) in dictionary_list]\n",
    "\n",
    "  combined_list = list(set(filtered_unigram + filterd_bigram + filterd_trigram + filterd_fourgram))\n",
    "  return combined_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "./csv-files/Question/LogisticReg.csv\n./csv-files/Question/neural_network.csv\n./csv-files/Question/random_forest.csv\n./csv-files/Question/PCA_SVD.csv\n./csv-files/Question/statistics.csv\n./csv-files/Question/naive_bayes.csv\n./csv-files/Question/TS_forecasting.csv\n./csv-files/Question/LinearReg.csv\n./csv-files/Question/MBA_AR.csv\n./csv-files/Question/KNN.csv\n./csv-files/Question/clustering.csv\n./csv-files/Question/code.csv\n./csv-files/Question/CF_RS.csv\n./csv-files/Question/text_mining.csv\n./csv-files/Question/SVM.csv\n./csv-files/Question/decision_tree.csv\n"
    }
   ],
   "source": [
    "question_path = \"./csv-files/Question\"\n",
    "columns_list = ['line', 'question', 'question_type']\n",
    "cdf = dataframe_reading_multiple_file(question_path, \"csv\", columns_list, 'infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  line                                           question        question_type\n0    1         When is Simple Linear Regression employed?  logistic regression\n1    2  when is simple linear regression employed in m...  logistic regression\n2    3  when is simple linear regression employed in d...  logistic regression\n3    4     when is simple linear regression employed in R  logistic regression\n4    5  when is simple linear regression employed in p...  logistic regression",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>line</th>\n      <th>question</th>\n      <th>question_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>When is Simple Linear Regression employed?</td>\n      <td>logistic regression</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>when is simple linear regression employed in m...</td>\n      <td>logistic regression</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>when is simple linear regression employed in d...</td>\n      <td>logistic regression</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>when is simple linear regression employed in R</td>\n      <td>logistic regression</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>when is simple linear regression employed in p...</td>\n      <td>logistic regression</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "cdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf['keywords'] = cdf.apply(lambda item: extract_keyword(item['question']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  line                                           question  \\\n0    1         When is Simple Linear Regression employed?   \n1    2  when is simple linear regression employed in m...   \n2    3  when is simple linear regression employed in d...   \n3    4     when is simple linear regression employed in R   \n4    5  when is simple linear regression employed in p...   \n\n         question_type                                           keywords  \n0  logistic regression                    [linear regression, regression]  \n1  logistic regression  [linear regression, regression, machine learni...  \n2  logistic regression  [linear regression, data science, regression, ...  \n3  logistic regression                 [linear regression, regression, r]  \n4  logistic regression            [linear regression, regression, python]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>line</th>\n      <th>question</th>\n      <th>question_type</th>\n      <th>keywords</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>When is Simple Linear Regression employed?</td>\n      <td>logistic regression</td>\n      <td>[linear regression, regression]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>when is simple linear regression employed in m...</td>\n      <td>logistic regression</td>\n      <td>[linear regression, regression, machine learni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>when is simple linear regression employed in d...</td>\n      <td>logistic regression</td>\n      <td>[linear regression, data science, regression, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>when is simple linear regression employed in R</td>\n      <td>logistic regression</td>\n      <td>[linear regression, regression, r]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>when is simple linear regression employed in p...</td>\n      <td>logistic regression</td>\n      <td>[linear regression, regression, python]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "cdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Collecting deepcorrect\n  Downloading deepcorrect-1.0.5-py2.py3-none-any.whl (14 kB)\nCollecting txt2txt==1.0.9\n  Downloading txt2txt-1.0.9-py2.py3-none-any.whl (5.4 kB)\nRequirement already satisfied: keras>=2.2.0 in /Users/hkesarva/anaconda3/lib/python3.7/site-packages (from txt2txt==1.0.9->deepcorrect) (2.3.1)\nRequirement already satisfied: numpy in /Users/hkesarva/anaconda3/lib/python3.7/site-packages (from txt2txt==1.0.9->deepcorrect) (1.18.1)\nRequirement already satisfied: pyyaml in /Users/hkesarva/anaconda3/lib/python3.7/site-packages (from keras>=2.2.0->txt2txt==1.0.9->deepcorrect) (5.3)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /Users/hkesarva/anaconda3/lib/python3.7/site-packages (from keras>=2.2.0->txt2txt==1.0.9->deepcorrect) (1.1.0)\nRequirement already satisfied: h5py in /Users/hkesarva/anaconda3/lib/python3.7/site-packages (from keras>=2.2.0->txt2txt==1.0.9->deepcorrect) (2.10.0)\nRequirement already satisfied: six>=1.9.0 in /Users/hkesarva/anaconda3/lib/python3.7/site-packages (from keras>=2.2.0->txt2txt==1.0.9->deepcorrect) (1.14.0)\nRequirement already satisfied: keras-applications>=1.0.6 in /Users/hkesarva/anaconda3/lib/python3.7/site-packages (from keras>=2.2.0->txt2txt==1.0.9->deepcorrect) (1.0.8)\nRequirement already satisfied: scipy>=0.14 in /Users/hkesarva/anaconda3/lib/python3.7/site-packages (from keras>=2.2.0->txt2txt==1.0.9->deepcorrect) (1.4.1)\nInstalling collected packages: txt2txt, deepcorrect\nSuccessfully installed deepcorrect-1.0.5 txt2txt-1.0.9\n"
    }
   ],
   "source": [
    "# !pip install deepcorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loading the params file\nInput encoding {'o': 2, '{': 3, '.': 4, 'J': 5, '0': 6, '1': 7, '<': 8, 'B': 9, 'd': 10, '£': 11, 'e': 12, '6': 13, '!': 14, 'O': 15, 'M': 16, 'X': 17, 'f': 18, 't': 19, 'C': 20, 'V': 21, 'z': 22, 'K': 23, '\\\\': 24, '9': 25, 'P': 26, 'S': 27, '/': 28, '₹': 29, 'F': 30, 'G': 31, '=': 32, '8': 33, ')': 34, '+': 35, ']': 36, 'U': 37, \"'\": 38, '\"': 39, 'g': 40, 'N': 41, 'r': 42, 'u': 43, '&': 44, '$': 45, 'x': 46, '%': 47, ':': 48, '@': 49, '^': 50, 'I': 51, 'L': 52, 'Z': 53, 'h': 54, 'W': 55, 'A': 56, 'v': 57, '?': 58, '2': 59, '~': 60, 's': 61, 'T': 62, 'R': 63, ',': 64, '|': 65, '4': 66, '>': 67, 'y': 68, '(': 69, '[': 70, 'k': 71, 'H': 72, 'l': 73, 'j': 74, '7': 75, 'n': 76, 'i': 77, 'D': 78, 'Q': 79, ' ': 80, 'm': 81, 'Y': 82, '*': 83, '}': 84, '#': 85, 'p': 86, 'q': 87, '5': 88, 'c': 89, '`': 90, 'a': 91, 'b': 92, 'w': 93, '3': 94, 'E': 95, ';': 96, '-': 97}\nInput decoding {2: 'o', 3: '{', 4: '.', 5: 'J', 6: '0', 7: '1', 8: '<', 9: 'B', 10: 'd', 11: '£', 12: 'e', 13: '6', 14: '!', 15: 'O', 16: 'M', 17: 'X', 18: 'f', 19: 't', 20: 'C', 21: 'V', 22: 'z', 23: 'K', 24: '\\\\', 25: '9', 26: 'P', 27: 'S', 28: '/', 29: '₹', 30: 'F', 31: 'G', 32: '=', 33: '8', 34: ')', 35: '+', 36: ']', 37: 'U', 38: \"'\", 39: '\"', 40: 'g', 41: 'N', 42: 'r', 43: 'u', 44: '&', 45: '$', 46: 'x', 47: '%', 48: ':', 49: '@', 50: '^', 51: 'I', 52: 'L', 53: 'Z', 54: 'h', 55: 'W', 56: 'A', 57: 'v', 58: '?', 59: '2', 60: '~', 61: 's', 62: 'T', 63: 'R', 64: ',', 65: '|', 66: '4', 67: '>', 68: 'y', 69: '(', 70: '[', 71: 'k', 72: 'H', 73: 'l', 74: 'j', 75: '7', 76: 'n', 77: 'i', 78: 'D', 79: 'Q', 80: ' ', 81: 'm', 82: 'Y', 83: '*', 84: '}', 85: '#', 86: 'p', 87: 'q', 88: '5', 89: 'c', 90: '`', 91: 'a', 92: 'b', 93: 'w', 94: '3', 95: 'E', 96: ';', 97: '-'}\nOutput encoding {'o': 2, '{': 3, '.': 4, 'J': 5, '0': 6, '1': 7, '<': 8, 'B': 9, 'd': 10, '£': 11, 'e': 12, '6': 13, '!': 14, 'O': 15, 'M': 16, 'X': 17, 'f': 18, 't': 19, 'C': 20, 'V': 21, 'z': 22, 'K': 23, '\\\\': 24, '9': 25, 'P': 26, 'S': 27, '/': 28, '₹': 29, 'F': 30, 'G': 31, '=': 32, '8': 33, ')': 34, '+': 35, ']': 36, 'U': 37, \"'\": 38, '\"': 39, 'g': 40, 'N': 41, 'r': 42, 'u': 43, '&': 44, '$': 45, 'x': 46, '%': 47, ':': 48, '@': 49, '^': 50, 'I': 51, 'L': 52, 'Z': 53, 'h': 54, 'W': 55, 'A': 56, 'v': 57, '?': 58, '2': 59, '~': 60, 's': 61, 'T': 62, 'R': 63, ',': 64, '|': 65, '4': 66, '>': 67, 'y': 68, '(': 69, '[': 70, 'k': 71, 'H': 72, 'l': 73, 'j': 74, '7': 75, 'n': 76, 'i': 77, 'D': 78, 'Q': 79, ' ': 80, 'm': 81, 'Y': 82, '*': 83, '}': 84, '#': 85, 'p': 86, 'q': 87, '5': 88, 'c': 89, '`': 90, 'a': 91, 'b': 92, 'w': 93, '3': 94, 'E': 95, ';': 96, '-': 97}\nOutput decoding {2: 'o', 3: '{', 4: '.', 5: 'J', 6: '0', 7: '1', 8: '<', 9: 'B', 10: 'd', 11: '£', 12: 'e', 13: '6', 14: '!', 15: 'O', 16: 'M', 17: 'X', 18: 'f', 19: 't', 20: 'C', 21: 'V', 22: 'z', 23: 'K', 24: '\\\\', 25: '9', 26: 'P', 27: 'S', 28: '/', 29: '₹', 30: 'F', 31: 'G', 32: '=', 33: '8', 34: ')', 35: '+', 36: ']', 37: 'U', 38: \"'\", 39: '\"', 40: 'g', 41: 'N', 42: 'r', 43: 'u', 44: '&', 45: '$', 46: 'x', 47: '%', 48: ':', 49: '@', 50: '^', 51: 'I', 52: 'L', 53: 'Z', 54: 'h', 55: 'W', 56: 'A', 57: 'v', 58: '?', 59: '2', 60: '~', 61: 's', 62: 'T', 63: 'R', 64: ',', 65: '|', 66: '4', 67: '>', 68: 'y', 69: '(', 70: '[', 71: 'k', 72: 'H', 73: 'l', 74: 'j', 75: '7', 76: 'n', 77: 'i', 78: 'D', 79: 'Q', 80: ' ', 81: 'm', 82: 'Y', 83: '*', 84: '}', 85: '#', 86: 'p', 87: 'q', 88: '5', 89: 'c', 90: '`', 91: 'a', 92: 'b', 93: 'w', 94: '3', 95: 'E', 96: ';', 97: '-'}\nModel: \"model_5\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_10 (InputLayer)           (None, 202)          0                                            \n__________________________________________________________________________________________________\ninput_9 (InputLayer)            (None, 202)          0                                            \n__________________________________________________________________________________________________\nembedding_10 (Embedding)        (None, 202, 256)     25088       input_10[0][0]                   \n__________________________________________________________________________________________________\nembedding_9 (Embedding)         (None, 202, 128)     12544       input_9[0][0]                    \n__________________________________________________________________________________________________\nlstm_10 (LSTM)                  (None, 202, 256)     525312      embedding_10[0][0]               \n__________________________________________________________________________________________________\nbidirectional_5 (Bidirectional) (None, 202, 256)     263168      embedding_9[0][0]                \n__________________________________________________________________________________________________\ndot_9 (Dot)                     (None, 202, 202)     0           lstm_10[0][0]                    \n                                                                 bidirectional_5[0][0]            \n__________________________________________________________________________________________________\nattention (Activation)          (None, 202, 202)     0           dot_9[0][0]                      \n__________________________________________________________________________________________________\ndot_10 (Dot)                    (None, 202, 256)     0           attention[0][0]                  \n                                                                 bidirectional_5[0][0]            \n__________________________________________________________________________________________________\nconcatenate_5 (Concatenate)     (None, 202, 512)     0           dot_10[0][0]                     \n                                                                 lstm_10[0][0]                    \n__________________________________________________________________________________________________\ntime_distributed_9 (TimeDistrib (None, 202, 128)     65664       concatenate_5[0][0]              \n__________________________________________________________________________________________________\ntime_distributed_10 (TimeDistri (None, 202, 98)      12642       time_distributed_9[0][0]         \n==================================================================================================\nTotal params: 904,418\nTrainable params: 904,418\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "from deepcorrect import DeepCorrect\n",
    "corrector = DeepCorrect('pre-trained-models/deeppunct_params_en', 'pre-trained-models/deeppunct_checkpoint_tatoeba_cornell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[{'sequence': 'What is nrmal distribtion.', 'prob': 0.5575786205068979}]\n"
    }
   ],
   "source": [
    "y = corrector.correct(\"what is nrmal distribtion\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}